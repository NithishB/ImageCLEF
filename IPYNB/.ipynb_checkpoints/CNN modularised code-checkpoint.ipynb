{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-19T19:41:42.826Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tifffile as tif\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from multiprocessing import Pool\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model, save_model\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T17:30:20.604537Z",
     "start_time": "2018-04-18T17:30:20.587495Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x_metadata, y_metadata, batch_size, crop_size):\n",
    "        self.x = x_metadata\n",
    "        self.y = y_metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.cp = crop_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        return np.array([np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:]\n",
    "                        for file_name in batch_x]), np.array(batch_y)         \n",
    "\n",
    "class CNN_Model:\n",
    "    \n",
    "    def __init__(self, directory):\n",
    "        \n",
    "        self.path = directory\n",
    "        self.classes = sorted(list(os.listdir(self.path+\"/train\")))\n",
    "        self.train_metadata_x = []\n",
    "        self.train_metadata_y = []\n",
    "        self.test_metadata_x = []\n",
    "        self.test_metadata_y = []\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            for im in os.listdir(self.path+\"/train/\"+cls):\n",
    "                self.train_metadata_x.append(self.path+\"/train/\"+cls+\"/\"+im)\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            for im in os.listdir(self.path+\"/test/\"+cls):\n",
    "                self.test_metadata_x.append(self.path+\"/test/\"+cls+\"/\"+im)\n",
    "        \n",
    "        np.random.shuffle(self.train_metadata_x)\n",
    "        np.random.shuffle(self.test_metadata_x)\n",
    "        \n",
    "        for p in self.train_metadata_x:\n",
    "            y = np.zeros(10, dtype=int)\n",
    "            y[self.classes.index(p.split(\"/\")[3])] = 1\n",
    "            self.train_metadata_y.append(y)\n",
    "            \n",
    "        for p in self.test_metadata_x:\n",
    "            y = np.zeros(10, dtype=int)\n",
    "            y[self.classes.index(p.split(\"/\")[3])] = 1\n",
    "            self.test_metadata_y.append(y)\n",
    "    \n",
    "    def model_create(self):\n",
    "        \n",
    "        classifier = Sequential()\n",
    "        # Step 1 - Convolution\n",
    "        classifier.add(Conv2D(filters=96, kernel_size=(2, 2), input_shape = (32,32,33), activation = 'relu'))\n",
    "        classifier.add(Conv2D(filters=288, kernel_size=(2, 2), activation = 'relu'))\n",
    "        classifier.add(Conv2D(filters=864, kernel_size=(2, 2), activation = 'relu'))\n",
    "        #classifier.add(Conv2D(filters=, kernel_size=(2, 2), activation = 'relu'))\n",
    "        classifier.add(MaxPool2D(pool_size = (2, 2)))\n",
    "        # Step 3 - Flattening\n",
    "        classifier.add(Flatten())\n",
    "        # Step 4 - Full connection\n",
    "        classifier.add(Dense(128, activation = 'relu'))\n",
    "        classifier.add(Dense(128, activation = 'tanh'))\n",
    "        classifier.add(Dense(10, activation = 'softmax'))\n",
    "        # Compiling the CNN\n",
    "        classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "        classifier.summary()\n",
    "        return classifier\n",
    "    \n",
    "    def fit_generator(self, num_epochs=10, batch_size=32, crop_size=16):        \n",
    "        try:\n",
    "            classifier = load_model(\"Code/Models/CNN_1.h5\")\n",
    "        except:\n",
    "            classifier = self.model_create()\n",
    "            train_data = ImageDataGenerator(self.train_metadata_x, self.train_metadata_y, batch_size, crop_size)\n",
    "            history = classifier.fit_generator(train_data, epochs=num_epochs, use_multiprocessing=True,shuffle=True)\n",
    "            classifier.save(\"Code/Models/CNN_1.h5\")\n",
    "        test_data = ImageDataGenerator(ob.test_metadata_x, ob.test_metadata_y, 64, 16)        \n",
    "        scores = classifier.evaluate_generator(test_data, use_multiprocessing=True)\n",
    "        print(\"Loss : \", scores[0])\n",
    "        print(\"Accuracy : \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T17:30:21.607616Z",
     "start_time": "2018-04-18T17:30:20.607776Z"
    }
   },
   "outputs": [],
   "source": [
    "ob = CNN_Model(directory=\"Data/Class wise Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-18T17:31:23.584676Z",
     "start_time": "2018-04-18T17:30:21.818141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 31, 31, 96)        12768     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 30, 30, 288)       110880    \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 29, 29, 864)       996192    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 864)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 169344)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               21676160  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 22,813,802\n",
      "Trainable params: 22,813,802\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "2903/2903 [==============================] - 1011s 348ms/step - loss: 0.5816 - acc: 0.8178\n",
      "Epoch 2/5\n",
      "2903/2903 [==============================] - 950s 327ms/step - loss: 0.5806 - acc: 0.8180\n",
      "Epoch 3/5\n",
      "2903/2903 [==============================] - 931s 321ms/step - loss: 0.5803 - acc: 0.8180\n",
      "Epoch 4/5\n",
      "2903/2903 [==============================] - 940s 324ms/step - loss: 0.5807 - acc: 0.8180\n",
      "Epoch 5/5\n",
      "2903/2903 [==============================] - 945s 326ms/step - loss: 0.5803 - acc: 0.8180\n"
     ]
    }
   ],
   "source": [
    "ob.fit_generator(num_epochs=5, batch_size=64, crop_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
