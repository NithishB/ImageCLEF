{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import tifffile as tif\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from multiprocessing import Pool\n",
    "from keras.utils import Sequence\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Reshape\n",
    "from collections import OrderedDict\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Permute\n",
    "from keras.models import load_model, save_model\n",
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataGenerator(Sequence):\n",
    "    \n",
    "    def __init__(self, x_metadata, y_metadata, batch_size, crop_size):\n",
    "        self.x = x_metadata\n",
    "        self.y = y_metadata\n",
    "        self.batch_size = batch_size\n",
    "        self.cp = crop_size\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        \n",
    "        arr = []\n",
    "        for file_name in batch_x:\n",
    "            arr.append(np.array([np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:], \n",
    "                         np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:],\n",
    "                         np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:],\n",
    "                         np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:],\n",
    "                         np.transpose(np.array(tif.imread(file_name), dtype=int)/255.0,\n",
    "                                     (1,2,0))[self.cp:-self.cp,self.cp:-self.cp,:]]))\n",
    "            \n",
    "        return np.array(arr), np.array(batch_y)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model:\n",
    "    \n",
    "    def __init__(self, directory):\n",
    "        \n",
    "        self.onehot = {}\n",
    "        self.path = directory\n",
    "        \n",
    "        df = pd.read_csv(\"occurrences_train.csv\",low_memory=False)\n",
    "        with open(\"Data/hierarchy_data.pkl\",\"rb\") as f:\n",
    "            hd = pkl.load(f)\n",
    "        with open(\"Data/class_encoding.pkl\",\"rb\") as f:\n",
    "            self.classes = pkl.load(f)\n",
    "        with open(\"Data/order_encoding.pkl\",\"rb\") as f:\n",
    "            self.orders = pkl.load(f)\n",
    "        with open(\"Data/family_encoding.pkl\",\"rb\") as f:\n",
    "            self.families = pkl.load(f)\n",
    "        with open(\"Data/genus_encoding.pkl\",\"rb\") as f:\n",
    "            self.genuses = pkl.load(f)\n",
    "        with open(\"Data/specie_encoding.pkl\",\"rb\") as f:\n",
    "            self.species = pkl.load(f)\n",
    "\n",
    "        self.onehot_output()\n",
    "\n",
    "        self.train_pathdata_x = []\n",
    "        self.train_seq_y = []\n",
    "        self.test_pathdata_x = []\n",
    "        self.test_seq_y = []\n",
    "        \n",
    "        for cls in hd.keys():\n",
    "            for order in hd[cls].keys():\n",
    "                for family in hd[cls][order].keys():\n",
    "                    for genus in hd[cls][order][family].keys():\n",
    "                        for specie in hd[cls][order][family][genus]:\n",
    "                            for im in os.listdir(self.path+\"train/\"+str(self.classes[cls])+\"/\"+str(self.orders[order])\n",
    "                                                 +\"/\"+str(self.families[family])+\"/\"+str(self.genuses[genus])+\"/\"+str(specie)):\n",
    "                                self.train_pathdata_x.append(self.path+\"train/\"+str(self.classes[cls])+\"/\"+str(self.orders[order])\n",
    "                                                             +\"/\"+str(self.families[family])+\"/\"+str(self.genuses[genus])+\"/\"+str(specie)+\"/\"\n",
    "                                                             +im)\n",
    "                            \n",
    "        for cls in hd.keys():\n",
    "            for order in hd[cls].keys():\n",
    "                for family in hd[cls][order].keys():\n",
    "                    for genus in hd[cls][order][family].keys():\n",
    "                        for specie in hd[cls][order][family][genus]:\n",
    "                            for im in os.listdir(self.path+\"test/\"+str(self.classes[cls])+\"/\"+str(self.orders[order])\n",
    "                                                 +\"/\"+str(self.families[family])+\"/\"+str(self.genuses[genus])+\"/\"+str(specie)):\n",
    "                                self.test_pathdata_x.append(self.path+\"test/\"+str(self.classes[cls])+\"/\"+str(self.orders[order])\n",
    "                                                             +\"/\"+str(self.families[family])+\"/\"+str(self.genuses[genus])+\"/\"+str(specie)+\"/\"\n",
    "                                                             +im)\n",
    "        \n",
    "        np.random.shuffle(self.train_pathdata_x)\n",
    "        np.random.shuffle(self.test_pathdata_x)\n",
    "        \n",
    "        for p in self.train_pathdata_x:\n",
    "            y = p.split(\"/\")\n",
    "            c = int(y[3])\n",
    "            o = int(y[4])\n",
    "            f = int(y[5])\n",
    "            g = int(y[6])\n",
    "            s = int(y[7])\n",
    "            self.train_seq_y.append([[c],[o],[f],[g],[s]])\n",
    "            \n",
    "        for p in self.test_pathdata_x:\n",
    "            y = p.split(\"/\")\n",
    "            c = int(y[3])\n",
    "            o = int(y[4])\n",
    "            f = int(y[5])\n",
    "            g = int(y[6])\n",
    "            s = int(y[7])\n",
    "            self.train_seq_y.append([[c],[o],[f],[g],[s]])\n",
    "    \n",
    "    def onehot_output(self):\n",
    "        for sp in self.species:\n",
    "            y = np.zeros(len(self.species))\n",
    "            y[list(self.species).index(sp)] = 1\n",
    "            self.onehot[sp] = y\n",
    "            \n",
    "    def model_create(self, time_steps=5, batch_size=32):\n",
    "        \n",
    "        classifier = Sequential()\n",
    "        # Step 1 - Convolution\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=96, kernel_size=(2, 2), input_shape = (32,32,33), activation = 'relu'), input_shape=(5,32,32,33)))\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=288, kernel_size=(2, 2), strides=(2,2), activation = 'relu')))\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=512, kernel_size=(3, 3), activation = 'relu')))\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=864, kernel_size=(4, 4), activation = 'relu')))\n",
    "        classifier.add(TimeDistributed(Conv2D(filters=864, kernel_size=(5, 5), activation = 'relu')))\n",
    "        #classifier.add(Conv2D(filters=, kernel_size=(2, 2), activation = 'relu'))\n",
    "        classifier.add(TimeDistributed(MaxPool2D(pool_size = (4, 4))))\n",
    "        # Step 3 - Flattening\n",
    "        classifier.add(TimeDistributed(Flatten()))\n",
    "        #classifier.add(Reshape((1,864)))\n",
    "\n",
    "        classifier.add(LSTM(50, return_sequences=True))\n",
    "        # Step 4 - Full connection\n",
    "        #classifier.add(Permute((1), input_shape=(5, 169344)))\n",
    "        classifier.add(Dense(128, activation = 'relu'))\n",
    "        classifier.add(Dense(1, activation = 'softmax'))\n",
    "        # Compiling the CNN\n",
    "        classifier.compile(optimizer = 'RMSprop', loss = 'mae', metrics = ['accuracy'])\n",
    "        classifier.summary()\n",
    "        return classifier\n",
    "    \n",
    "    def fit_generator(self, num_epochs=10, batch_size=32, crop_size=16, time_steps=5):        \n",
    "        try:\n",
    "            classifier = load_model(\"Code/Models/CNN-RNN_1.h5\")\n",
    "        except:\n",
    "            print(\"Training\")\n",
    "            classifier = self.model_create(time_steps=time_steps, batch_size=batch_size)\n",
    "            train_data = ImageDataGenerator(self.train_pathdata_x, self.train_seq_y, batch_size, crop_size)\n",
    "            history = classifier.fit_generator(train_data, epochs=num_epochs, use_multiprocessing=True,shuffle=True)\n",
    "            classifier.save(\"Code/Models/CNN-RNN_1.h5\")\n",
    "        print(\"Testing\")\n",
    "        train_data = ImageDataGenerator(self.test_pathdata_x, self.test_seq_y, batch_size, crop_size)\n",
    "        scores = classifier.evaluate_generator(test_data, use_multiprocessing=True)\n",
    "        print(\"Loss : \", scores[0])\n",
    "        print(\"Accuracy : \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = CNN_Model(\"Data/Hierarchial Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob.fit_generator(num_epochs=10, batch_size=30, time_steps=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
