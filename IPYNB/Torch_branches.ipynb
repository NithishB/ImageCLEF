{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ShapesDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx, 0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:].as_matrix()\n",
    "        landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'image': image, 'landmarks': landmarks}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Circle': 2, 'Hexagon': 0, 'Pentagon': 3, 'Rectangle': 4, 'Triangle': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = dict((c, i) for i, c in enumerate(os.listdir('Shapes/Train/')))\n",
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    shape=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        for image in os.listdir(folder+str(filename)):\n",
    "            img = cv2.imread(os.path.join(folder+str(filename),image))\n",
    "            if img is not None:\n",
    "                images.append(img.transpose((2, 0, 1)) )\n",
    "                shape.append(dic[str(filename)])\n",
    "    return images,shape    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapesDataset(Dataset):\n",
    "\n",
    "    def __init__(self,root_dir, transform=None):\n",
    "        self.image=[]\n",
    "        self.shape=[]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        dic = dict((c, i) for i, c in enumerate(os.listdir(self.root_dir)))\n",
    "        for filename in os.listdir(self.root_dir):\n",
    "            for image in os.listdir(self.root_dir+str(filename)):\n",
    "                img = cv2.imread(os.path.join(self.root_dir+str(filename),image))\n",
    "                if img is not None:\n",
    "                    self.image.append(img.transpose((2,0,1)))\n",
    "                    self.shape.append(dic[str(filename)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.shape)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #if self.transform:\n",
    "            #sample = self.transform(sample) \n",
    "        self.image=np.array(self.image)\n",
    "        return torch.from_numpy(self.image[idx]/255.0),(self.shape[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3857, 3, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i,s=load_images_from_folder('Shapes/Test/')\n",
    "# c=0\n",
    "# for j in range(len(s)):\n",
    "#     if(s[j]=='Circle'):\n",
    "#         c+=1\n",
    "#print(i[2000],s[2000]) \n",
    "#type(s)\n",
    "np.array(i).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 16\n",
    "\n",
    "# Dataset\n",
    "train_dataset = ShapesDataset(root_dir='Shapes/Train/',\n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = ShapesDataset(root_dir='Shapes/Test/',\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0811b7f3ee0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "np.array(train_dataset.__getitem__(2)).shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Branched_CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels):\n",
    "        super(Branched_CNN, self).__init__()\n",
    "        self.branch1x1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "\n",
    "        self.branch5x5_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = nn.Conv2d(16, 24, kernel_size=5, padding=2)\n",
    "\n",
    "        self.branch3x3_1 = nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
    "        self.branch3x3_3 = nn.Conv2d(24, 24, kernel_size=3, padding=1)\n",
    "\n",
    "        self.branch_pool = nn.Conv2d(in_channels, 24, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x.float())\n",
    "\n",
    "        branch5x5 = self.branch5x5_1(x.float())\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "\n",
    "        branch3x3 = self.branch3x3_1(x.float())\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "        branch3x3 = self.branch3x3_3(branch3x3)\n",
    "\n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "\n",
    "        outputs = [branch1x1, branch5x5, branch3x3, branch_pool]\n",
    "        return torch.cat(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(88, 16, kernel_size=3)\n",
    "\n",
    "        self.network1 = Branched_CNN(in_channels=64)\n",
    "        self.network2 = Branched_CNN(in_channels=16)\n",
    "\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(2200,1600)\n",
    "        self.fc2 = nn.Linear(1600,800)\n",
    "        self.fc3 = nn.Linear(800,128)\n",
    "        self.fc4 = nn.Linear(128,16)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = F.relu(self.mp(self.conv1(x.float())))\n",
    "       \n",
    "        x = self.network1(x.float())\n",
    "        x = F.relu(self.mp(self.conv2(x.float())))\n",
    "        x = self.network2(x.float())\n",
    "        x = x.view(in_size, -1)  # flatten the tensor\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(88, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (network1): Branched_CNN(\n",
       "    (branch1x1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch5x5_1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch5x5_2): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (branch3x3_1): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch3x3_2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (branch3x3_3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (branch_pool): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (network2): Branched_CNN(\n",
       "    (branch1x1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch5x5_1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch5x5_2): Conv2d(16, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (branch3x3_1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (branch3x3_2): Conv2d(16, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (branch3x3_3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (branch_pool): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (mp): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (fc1): Linear(in_features=2200, out_features=1600, bias=True)\n",
       "  (fc2): Linear(in_features=1600, out_features=800, bias=True)\n",
       "  (fc3): Linear(in_features=800, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=16, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(target,\" :\",output)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).data[0]\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/17168 (0%)]\tLoss: 2.740190\n",
      "Train Epoch: 1 [160/17168 (1%)]\tLoss: 2.615175\n",
      "Train Epoch: 1 [320/17168 (2%)]\tLoss: 2.369420\n",
      "Train Epoch: 1 [480/17168 (3%)]\tLoss: 1.652780\n",
      "Train Epoch: 1 [640/17168 (4%)]\tLoss: 1.717301\n",
      "Train Epoch: 1 [800/17168 (5%)]\tLoss: 1.574546\n",
      "Train Epoch: 1 [960/17168 (6%)]\tLoss: 1.458035\n",
      "Train Epoch: 1 [1120/17168 (7%)]\tLoss: 1.603423\n",
      "Train Epoch: 1 [1280/17168 (7%)]\tLoss: 1.770942\n",
      "Train Epoch: 1 [1440/17168 (8%)]\tLoss: 1.758655\n",
      "Train Epoch: 1 [1600/17168 (9%)]\tLoss: 1.556695\n",
      "Train Epoch: 1 [1760/17168 (10%)]\tLoss: 1.673056\n",
      "Train Epoch: 1 [1920/17168 (11%)]\tLoss: 1.785106\n",
      "Train Epoch: 1 [2080/17168 (12%)]\tLoss: 1.548995\n",
      "Train Epoch: 1 [2240/17168 (13%)]\tLoss: 1.576725\n",
      "Train Epoch: 1 [2400/17168 (14%)]\tLoss: 1.578160\n",
      "Train Epoch: 1 [2560/17168 (15%)]\tLoss: 1.709205\n",
      "Train Epoch: 1 [2720/17168 (16%)]\tLoss: 1.600527\n",
      "Train Epoch: 1 [2880/17168 (17%)]\tLoss: 1.547848\n",
      "Train Epoch: 1 [3040/17168 (18%)]\tLoss: 1.672262\n",
      "Train Epoch: 1 [3200/17168 (19%)]\tLoss: 1.793726\n",
      "Train Epoch: 1 [3360/17168 (20%)]\tLoss: 1.779836\n",
      "Train Epoch: 1 [3520/17168 (21%)]\tLoss: 1.584724\n",
      "Train Epoch: 1 [3680/17168 (21%)]\tLoss: 1.528420\n",
      "Train Epoch: 1 [3840/17168 (22%)]\tLoss: 1.664751\n",
      "Train Epoch: 1 [4000/17168 (23%)]\tLoss: 1.458275\n",
      "Train Epoch: 1 [4160/17168 (24%)]\tLoss: 1.410407\n",
      "Train Epoch: 1 [4320/17168 (25%)]\tLoss: 1.492191\n",
      "Train Epoch: 1 [4480/17168 (26%)]\tLoss: 1.464222\n",
      "Train Epoch: 1 [4640/17168 (27%)]\tLoss: 1.468400\n",
      "Train Epoch: 1 [4800/17168 (28%)]\tLoss: 1.545539\n",
      "Train Epoch: 1 [4960/17168 (29%)]\tLoss: 1.569425\n",
      "Train Epoch: 1 [5120/17168 (30%)]\tLoss: 1.494342\n",
      "Train Epoch: 1 [5280/17168 (31%)]\tLoss: 1.334813\n",
      "Train Epoch: 1 [5440/17168 (32%)]\tLoss: 1.370224\n",
      "Train Epoch: 1 [5600/17168 (33%)]\tLoss: 1.273743\n",
      "Train Epoch: 1 [5760/17168 (34%)]\tLoss: 1.602751\n",
      "Train Epoch: 1 [5920/17168 (34%)]\tLoss: 1.529141\n",
      "Train Epoch: 1 [6080/17168 (35%)]\tLoss: 1.365219\n",
      "Train Epoch: 1 [6240/17168 (36%)]\tLoss: 1.413543\n",
      "Train Epoch: 1 [6400/17168 (37%)]\tLoss: 1.223728\n",
      "Train Epoch: 1 [6560/17168 (38%)]\tLoss: 1.378338\n",
      "Train Epoch: 1 [6720/17168 (39%)]\tLoss: 1.506192\n",
      "Train Epoch: 1 [6880/17168 (40%)]\tLoss: 1.474037\n",
      "Train Epoch: 1 [7040/17168 (41%)]\tLoss: 1.055292\n",
      "Train Epoch: 1 [7200/17168 (42%)]\tLoss: 1.438592\n",
      "Train Epoch: 1 [7360/17168 (43%)]\tLoss: 1.358056\n",
      "Train Epoch: 1 [7520/17168 (44%)]\tLoss: 1.370940\n",
      "Train Epoch: 1 [7680/17168 (45%)]\tLoss: 1.321319\n",
      "Train Epoch: 1 [7840/17168 (46%)]\tLoss: 1.312065\n",
      "Train Epoch: 1 [8000/17168 (47%)]\tLoss: 1.279442\n",
      "Train Epoch: 1 [8160/17168 (48%)]\tLoss: 1.164644\n",
      "Train Epoch: 1 [8320/17168 (48%)]\tLoss: 1.442767\n",
      "Train Epoch: 1 [8480/17168 (49%)]\tLoss: 1.572041\n",
      "Train Epoch: 1 [8640/17168 (50%)]\tLoss: 1.247872\n",
      "Train Epoch: 1 [8800/17168 (51%)]\tLoss: 1.357651\n",
      "Train Epoch: 1 [8960/17168 (52%)]\tLoss: 1.250814\n",
      "Train Epoch: 1 [9120/17168 (53%)]\tLoss: 1.395197\n",
      "Train Epoch: 1 [9280/17168 (54%)]\tLoss: 1.335279\n",
      "Train Epoch: 1 [9440/17168 (55%)]\tLoss: 1.285638\n",
      "Train Epoch: 1 [9600/17168 (56%)]\tLoss: 1.439980\n",
      "Train Epoch: 1 [9760/17168 (57%)]\tLoss: 1.332134\n",
      "Train Epoch: 1 [9920/17168 (58%)]\tLoss: 1.404583\n",
      "Train Epoch: 1 [10080/17168 (59%)]\tLoss: 1.719164\n",
      "Train Epoch: 1 [10240/17168 (60%)]\tLoss: 1.404719\n",
      "Train Epoch: 1 [10400/17168 (61%)]\tLoss: 1.160586\n",
      "Train Epoch: 1 [10560/17168 (62%)]\tLoss: 1.410365\n",
      "Train Epoch: 1 [10720/17168 (62%)]\tLoss: 1.139066\n",
      "Train Epoch: 1 [10880/17168 (63%)]\tLoss: 1.831943\n",
      "Train Epoch: 1 [11040/17168 (64%)]\tLoss: 1.455019\n",
      "Train Epoch: 1 [11200/17168 (65%)]\tLoss: 1.483948\n",
      "Train Epoch: 1 [11360/17168 (66%)]\tLoss: 1.538444\n",
      "Train Epoch: 1 [11520/17168 (67%)]\tLoss: 1.312263\n",
      "Train Epoch: 1 [11680/17168 (68%)]\tLoss: 1.451776\n",
      "Train Epoch: 1 [11840/17168 (69%)]\tLoss: 1.445229\n",
      "Train Epoch: 1 [12000/17168 (70%)]\tLoss: 1.365528\n",
      "Train Epoch: 1 [12160/17168 (71%)]\tLoss: 1.298813\n",
      "Train Epoch: 1 [12320/17168 (72%)]\tLoss: 1.286837\n",
      "Train Epoch: 1 [12480/17168 (73%)]\tLoss: 1.660236\n",
      "Train Epoch: 1 [12640/17168 (74%)]\tLoss: 1.350914\n",
      "Train Epoch: 1 [12800/17168 (75%)]\tLoss: 1.460394\n",
      "Train Epoch: 1 [12960/17168 (75%)]\tLoss: 1.182742\n",
      "Train Epoch: 1 [13120/17168 (76%)]\tLoss: 1.291880\n",
      "Train Epoch: 1 [13280/17168 (77%)]\tLoss: 1.111769\n",
      "Train Epoch: 1 [13440/17168 (78%)]\tLoss: 1.437873\n",
      "Train Epoch: 1 [13600/17168 (79%)]\tLoss: 1.229044\n",
      "Train Epoch: 1 [13760/17168 (80%)]\tLoss: 1.341385\n",
      "Train Epoch: 1 [13920/17168 (81%)]\tLoss: 1.174244\n",
      "Train Epoch: 1 [14080/17168 (82%)]\tLoss: 1.510188\n",
      "Train Epoch: 1 [14240/17168 (83%)]\tLoss: 1.257385\n",
      "Train Epoch: 1 [14400/17168 (84%)]\tLoss: 1.572222\n",
      "Train Epoch: 1 [14560/17168 (85%)]\tLoss: 1.541437\n",
      "Train Epoch: 1 [14720/17168 (86%)]\tLoss: 1.429903\n",
      "Train Epoch: 1 [14880/17168 (87%)]\tLoss: 1.281193\n",
      "Train Epoch: 1 [15040/17168 (88%)]\tLoss: 1.321613\n",
      "Train Epoch: 1 [15200/17168 (89%)]\tLoss: 1.214161\n",
      "Train Epoch: 1 [15360/17168 (89%)]\tLoss: 1.466096\n",
      "Train Epoch: 1 [15520/17168 (90%)]\tLoss: 1.223834\n",
      "Train Epoch: 1 [15680/17168 (91%)]\tLoss: 1.313898\n",
      "Train Epoch: 1 [15840/17168 (92%)]\tLoss: 1.194171\n",
      "Train Epoch: 1 [16000/17168 (93%)]\tLoss: 1.326823\n",
      "Train Epoch: 1 [16160/17168 (94%)]\tLoss: 1.482185\n",
      "Train Epoch: 1 [16320/17168 (95%)]\tLoss: 1.299503\n",
      "Train Epoch: 1 [16480/17168 (96%)]\tLoss: 1.714703\n",
      "Train Epoch: 1 [16640/17168 (97%)]\tLoss: 1.228851\n",
      "Train Epoch: 1 [16800/17168 (98%)]\tLoss: 1.372877\n",
      "Train Epoch: 1 [16960/17168 (99%)]\tLoss: 1.249356\n",
      "Train Epoch: 1 [17120/17168 (100%)]\tLoss: 1.346395\n",
      "\n",
      "Test set: Average loss: 1.4203, Accuracy: 1010/3857 (26%)\n",
      "\n",
      "Train Epoch: 2 [0/17168 (0%)]\tLoss: 1.421441\n",
      "Train Epoch: 2 [160/17168 (1%)]\tLoss: 1.337380\n",
      "Train Epoch: 2 [320/17168 (2%)]\tLoss: 1.222110\n",
      "Train Epoch: 2 [480/17168 (3%)]\tLoss: 1.448274\n",
      "Train Epoch: 2 [640/17168 (4%)]\tLoss: 1.386485\n",
      "Train Epoch: 2 [800/17168 (5%)]\tLoss: 1.396503\n",
      "Train Epoch: 2 [960/17168 (6%)]\tLoss: 1.432460\n",
      "Train Epoch: 2 [1120/17168 (7%)]\tLoss: 1.357536\n",
      "Train Epoch: 2 [1280/17168 (7%)]\tLoss: 1.539579\n",
      "Train Epoch: 2 [1440/17168 (8%)]\tLoss: 1.293996\n",
      "Train Epoch: 2 [1600/17168 (9%)]\tLoss: 1.445961\n",
      "Train Epoch: 2 [1760/17168 (10%)]\tLoss: 1.248038\n",
      "Train Epoch: 2 [1920/17168 (11%)]\tLoss: 1.514932\n",
      "Train Epoch: 2 [2080/17168 (12%)]\tLoss: 1.432582\n",
      "Train Epoch: 2 [2240/17168 (13%)]\tLoss: 1.297202\n",
      "Train Epoch: 2 [2400/17168 (14%)]\tLoss: 1.247996\n",
      "Train Epoch: 2 [2560/17168 (15%)]\tLoss: 1.262391\n",
      "Train Epoch: 2 [2720/17168 (16%)]\tLoss: 1.388302\n",
      "Train Epoch: 2 [2880/17168 (17%)]\tLoss: 1.156942\n",
      "Train Epoch: 2 [3040/17168 (18%)]\tLoss: 1.235353\n",
      "Train Epoch: 2 [3200/17168 (19%)]\tLoss: 1.404333\n",
      "Train Epoch: 2 [3360/17168 (20%)]\tLoss: 1.402803\n",
      "Train Epoch: 2 [3520/17168 (21%)]\tLoss: 1.238545\n",
      "Train Epoch: 2 [3680/17168 (21%)]\tLoss: 1.258359\n",
      "Train Epoch: 2 [3840/17168 (22%)]\tLoss: 1.372854\n",
      "Train Epoch: 2 [4000/17168 (23%)]\tLoss: 1.265422\n",
      "Train Epoch: 2 [4160/17168 (24%)]\tLoss: 1.280808\n",
      "Train Epoch: 2 [4320/17168 (25%)]\tLoss: 1.314560\n",
      "Train Epoch: 2 [4480/17168 (26%)]\tLoss: 1.209883\n",
      "Train Epoch: 2 [4640/17168 (27%)]\tLoss: 1.418160\n",
      "Train Epoch: 2 [4800/17168 (28%)]\tLoss: 1.322788\n",
      "Train Epoch: 2 [4960/17168 (29%)]\tLoss: 1.443360\n",
      "Train Epoch: 2 [5120/17168 (30%)]\tLoss: 1.400386\n",
      "Train Epoch: 2 [5280/17168 (31%)]\tLoss: 1.302963\n",
      "Train Epoch: 2 [5440/17168 (32%)]\tLoss: 1.257237\n",
      "Train Epoch: 2 [5600/17168 (33%)]\tLoss: 1.401063\n",
      "Train Epoch: 2 [5760/17168 (34%)]\tLoss: 1.428725\n",
      "Train Epoch: 2 [5920/17168 (34%)]\tLoss: 1.687139\n",
      "Train Epoch: 2 [6080/17168 (35%)]\tLoss: 1.409274\n",
      "Train Epoch: 2 [6240/17168 (36%)]\tLoss: 1.579502\n",
      "Train Epoch: 2 [6400/17168 (37%)]\tLoss: 1.340605\n",
      "Train Epoch: 2 [6560/17168 (38%)]\tLoss: 1.405229\n",
      "Train Epoch: 2 [6720/17168 (39%)]\tLoss: 1.322353\n",
      "Train Epoch: 2 [6880/17168 (40%)]\tLoss: 1.337172\n",
      "Train Epoch: 2 [7040/17168 (41%)]\tLoss: 1.371131\n",
      "Train Epoch: 2 [7200/17168 (42%)]\tLoss: 1.502428\n",
      "Train Epoch: 2 [7360/17168 (43%)]\tLoss: 1.149493\n",
      "Train Epoch: 2 [7520/17168 (44%)]\tLoss: 1.302706\n",
      "Train Epoch: 2 [7680/17168 (45%)]\tLoss: 1.272309\n",
      "Train Epoch: 2 [7840/17168 (46%)]\tLoss: 1.426552\n",
      "Train Epoch: 2 [8000/17168 (47%)]\tLoss: 1.370170\n",
      "Train Epoch: 2 [8160/17168 (48%)]\tLoss: 1.111286\n",
      "Train Epoch: 2 [8320/17168 (48%)]\tLoss: 1.212741\n",
      "Train Epoch: 2 [8480/17168 (49%)]\tLoss: 1.317697\n",
      "Train Epoch: 2 [8640/17168 (50%)]\tLoss: 1.652964\n",
      "Train Epoch: 2 [8800/17168 (51%)]\tLoss: 1.582298\n",
      "Train Epoch: 2 [8960/17168 (52%)]\tLoss: 1.462923\n",
      "Train Epoch: 2 [9120/17168 (53%)]\tLoss: 1.518512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [9280/17168 (54%)]\tLoss: 1.255319\n",
      "Train Epoch: 2 [9440/17168 (55%)]\tLoss: 1.210909\n",
      "Train Epoch: 2 [9600/17168 (56%)]\tLoss: 1.556051\n",
      "Train Epoch: 2 [9760/17168 (57%)]\tLoss: 1.299196\n",
      "Train Epoch: 2 [9920/17168 (58%)]\tLoss: 1.212731\n",
      "Train Epoch: 2 [10080/17168 (59%)]\tLoss: 1.359152\n",
      "Train Epoch: 2 [10240/17168 (60%)]\tLoss: 1.365412\n",
      "Train Epoch: 2 [10400/17168 (61%)]\tLoss: 1.339549\n",
      "Train Epoch: 2 [10560/17168 (62%)]\tLoss: 1.193452\n",
      "Train Epoch: 2 [10720/17168 (62%)]\tLoss: 1.318867\n",
      "Train Epoch: 2 [10880/17168 (63%)]\tLoss: 1.191248\n",
      "Train Epoch: 2 [11040/17168 (64%)]\tLoss: 1.255425\n",
      "Train Epoch: 2 [11200/17168 (65%)]\tLoss: 0.991801\n",
      "Train Epoch: 2 [11360/17168 (66%)]\tLoss: 1.363989\n",
      "Train Epoch: 2 [11520/17168 (67%)]\tLoss: 1.121948\n",
      "Train Epoch: 2 [11680/17168 (68%)]\tLoss: 1.162571\n",
      "Train Epoch: 2 [11840/17168 (69%)]\tLoss: 1.133628\n",
      "Train Epoch: 2 [12000/17168 (70%)]\tLoss: 1.292998\n",
      "Train Epoch: 2 [12160/17168 (71%)]\tLoss: 1.266446\n",
      "Train Epoch: 2 [12320/17168 (72%)]\tLoss: 1.292065\n",
      "Train Epoch: 2 [12480/17168 (73%)]\tLoss: 1.323926\n",
      "Train Epoch: 2 [12640/17168 (74%)]\tLoss: 1.421348\n",
      "Train Epoch: 2 [12800/17168 (75%)]\tLoss: 1.163512\n",
      "Train Epoch: 2 [12960/17168 (75%)]\tLoss: 1.324932\n",
      "Train Epoch: 2 [13120/17168 (76%)]\tLoss: 1.163174\n",
      "Train Epoch: 2 [13280/17168 (77%)]\tLoss: 1.055454\n",
      "Train Epoch: 2 [13440/17168 (78%)]\tLoss: 1.267661\n",
      "Train Epoch: 2 [13600/17168 (79%)]\tLoss: 1.504930\n",
      "Train Epoch: 2 [13760/17168 (80%)]\tLoss: 1.228571\n",
      "Train Epoch: 2 [13920/17168 (81%)]\tLoss: 1.322446\n",
      "Train Epoch: 2 [14080/17168 (82%)]\tLoss: 1.249430\n",
      "Train Epoch: 2 [14240/17168 (83%)]\tLoss: 1.538743\n",
      "Train Epoch: 2 [14400/17168 (84%)]\tLoss: 1.203125\n",
      "Train Epoch: 2 [14560/17168 (85%)]\tLoss: 1.214837\n",
      "Train Epoch: 2 [14720/17168 (86%)]\tLoss: 1.273541\n",
      "Train Epoch: 2 [14880/17168 (87%)]\tLoss: 1.470023\n",
      "Train Epoch: 2 [15040/17168 (88%)]\tLoss: 1.061967\n",
      "Train Epoch: 2 [15200/17168 (89%)]\tLoss: 1.669238\n",
      "Train Epoch: 2 [15360/17168 (89%)]\tLoss: 1.279130\n",
      "Train Epoch: 2 [15520/17168 (90%)]\tLoss: 1.162016\n",
      "Train Epoch: 2 [15680/17168 (91%)]\tLoss: 1.420363\n",
      "Train Epoch: 2 [15840/17168 (92%)]\tLoss: 1.289889\n",
      "Train Epoch: 2 [16000/17168 (93%)]\tLoss: 1.697914\n",
      "Train Epoch: 2 [16160/17168 (94%)]\tLoss: 1.459926\n",
      "Train Epoch: 2 [16320/17168 (95%)]\tLoss: 1.452127\n",
      "Train Epoch: 2 [16480/17168 (96%)]\tLoss: 1.298714\n",
      "Train Epoch: 2 [16640/17168 (97%)]\tLoss: 1.266442\n",
      "Train Epoch: 2 [16800/17168 (98%)]\tLoss: 1.308559\n",
      "Train Epoch: 2 [16960/17168 (99%)]\tLoss: 1.481651\n",
      "Train Epoch: 2 [17120/17168 (100%)]\tLoss: 1.314677\n",
      "\n",
      "Test set: Average loss: 1.4443, Accuracy: 1079/3857 (28%)\n",
      "\n",
      "Train Epoch: 3 [0/17168 (0%)]\tLoss: 1.348740\n",
      "Train Epoch: 3 [160/17168 (1%)]\tLoss: 1.459826\n",
      "Train Epoch: 3 [320/17168 (2%)]\tLoss: 1.330379\n",
      "Train Epoch: 3 [480/17168 (3%)]\tLoss: 1.471969\n",
      "Train Epoch: 3 [640/17168 (4%)]\tLoss: 1.367665\n",
      "Train Epoch: 3 [800/17168 (5%)]\tLoss: 1.304524\n",
      "Train Epoch: 3 [960/17168 (6%)]\tLoss: 1.424072\n",
      "Train Epoch: 3 [1120/17168 (7%)]\tLoss: 1.094743\n",
      "Train Epoch: 3 [1280/17168 (7%)]\tLoss: 1.497815\n",
      "Train Epoch: 3 [1440/17168 (8%)]\tLoss: 1.373942\n",
      "Train Epoch: 3 [1600/17168 (9%)]\tLoss: 1.307694\n",
      "Train Epoch: 3 [1760/17168 (10%)]\tLoss: 1.256936\n",
      "Train Epoch: 3 [1920/17168 (11%)]\tLoss: 1.239612\n",
      "Train Epoch: 3 [2080/17168 (12%)]\tLoss: 1.325104\n",
      "Train Epoch: 3 [2240/17168 (13%)]\tLoss: 1.398046\n",
      "Train Epoch: 3 [2400/17168 (14%)]\tLoss: 1.422279\n",
      "Train Epoch: 3 [2560/17168 (15%)]\tLoss: 2.103466\n",
      "Train Epoch: 3 [2720/17168 (16%)]\tLoss: 1.456181\n",
      "Train Epoch: 3 [2880/17168 (17%)]\tLoss: 1.248699\n",
      "Train Epoch: 3 [3040/17168 (18%)]\tLoss: 1.473752\n",
      "Train Epoch: 3 [3200/17168 (19%)]\tLoss: 1.496684\n",
      "Train Epoch: 3 [3360/17168 (20%)]\tLoss: 1.478824\n",
      "Train Epoch: 3 [3520/17168 (21%)]\tLoss: 1.263729\n",
      "Train Epoch: 3 [3680/17168 (21%)]\tLoss: 1.191579\n",
      "Train Epoch: 3 [3840/17168 (22%)]\tLoss: 1.413098\n",
      "Train Epoch: 3 [4000/17168 (23%)]\tLoss: 1.283934\n",
      "Train Epoch: 3 [4160/17168 (24%)]\tLoss: 1.272469\n",
      "Train Epoch: 3 [4320/17168 (25%)]\tLoss: 1.271166\n",
      "Train Epoch: 3 [4480/17168 (26%)]\tLoss: 1.068780\n",
      "Train Epoch: 3 [4640/17168 (27%)]\tLoss: 1.281698\n",
      "Train Epoch: 3 [4800/17168 (28%)]\tLoss: 1.588975\n",
      "Train Epoch: 3 [4960/17168 (29%)]\tLoss: 1.249735\n",
      "Train Epoch: 3 [5120/17168 (30%)]\tLoss: 1.354838\n",
      "Train Epoch: 3 [5280/17168 (31%)]\tLoss: 1.415424\n",
      "Train Epoch: 3 [5440/17168 (32%)]\tLoss: 1.138972\n",
      "Train Epoch: 3 [5600/17168 (33%)]\tLoss: 1.148531\n",
      "Train Epoch: 3 [5760/17168 (34%)]\tLoss: 1.216512\n",
      "Train Epoch: 3 [5920/17168 (34%)]\tLoss: 1.276576\n",
      "Train Epoch: 3 [6080/17168 (35%)]\tLoss: 1.196686\n",
      "Train Epoch: 3 [6240/17168 (36%)]\tLoss: 1.339080\n",
      "Train Epoch: 3 [6400/17168 (37%)]\tLoss: 1.088611\n",
      "Train Epoch: 3 [6560/17168 (38%)]\tLoss: 1.370651\n",
      "Train Epoch: 3 [6720/17168 (39%)]\tLoss: 1.619355\n",
      "Train Epoch: 3 [6880/17168 (40%)]\tLoss: 1.303354\n",
      "Train Epoch: 3 [7040/17168 (41%)]\tLoss: 1.631695\n",
      "Train Epoch: 3 [7200/17168 (42%)]\tLoss: 1.392039\n",
      "Train Epoch: 3 [7360/17168 (43%)]\tLoss: 1.155447\n",
      "Train Epoch: 3 [7520/17168 (44%)]\tLoss: 1.310528\n",
      "Train Epoch: 3 [7680/17168 (45%)]\tLoss: 1.277791\n",
      "Train Epoch: 3 [7840/17168 (46%)]\tLoss: 1.315917\n",
      "Train Epoch: 3 [8000/17168 (47%)]\tLoss: 1.328046\n",
      "Train Epoch: 3 [8160/17168 (48%)]\tLoss: 1.321383\n",
      "Train Epoch: 3 [8320/17168 (48%)]\tLoss: 1.312685\n",
      "Train Epoch: 3 [8480/17168 (49%)]\tLoss: 1.180884\n",
      "Train Epoch: 3 [8640/17168 (50%)]\tLoss: 1.109742\n",
      "Train Epoch: 3 [8800/17168 (51%)]\tLoss: 1.960242\n",
      "Train Epoch: 3 [8960/17168 (52%)]\tLoss: 1.514423\n",
      "Train Epoch: 3 [9120/17168 (53%)]\tLoss: 1.160720\n",
      "Train Epoch: 3 [9280/17168 (54%)]\tLoss: 1.716250\n",
      "Train Epoch: 3 [9440/17168 (55%)]\tLoss: 1.331558\n",
      "Train Epoch: 3 [9600/17168 (56%)]\tLoss: 1.417095\n",
      "Train Epoch: 3 [9760/17168 (57%)]\tLoss: 1.508726\n",
      "Train Epoch: 3 [9920/17168 (58%)]\tLoss: 1.299452\n",
      "Train Epoch: 3 [10080/17168 (59%)]\tLoss: 1.350389\n",
      "Train Epoch: 3 [10240/17168 (60%)]\tLoss: 1.375824\n",
      "Train Epoch: 3 [10400/17168 (61%)]\tLoss: 1.179617\n",
      "Train Epoch: 3 [10560/17168 (62%)]\tLoss: 1.420128\n",
      "Train Epoch: 3 [10720/17168 (62%)]\tLoss: 1.403254\n",
      "Train Epoch: 3 [10880/17168 (63%)]\tLoss: 1.653978\n",
      "Train Epoch: 3 [11040/17168 (64%)]\tLoss: 1.458233\n",
      "Train Epoch: 3 [11200/17168 (65%)]\tLoss: 1.305432\n",
      "Train Epoch: 3 [11360/17168 (66%)]\tLoss: 1.140266\n",
      "Train Epoch: 3 [11520/17168 (67%)]\tLoss: 1.272295\n",
      "Train Epoch: 3 [11680/17168 (68%)]\tLoss: 1.140915\n",
      "Train Epoch: 3 [11840/17168 (69%)]\tLoss: 1.542621\n",
      "Train Epoch: 3 [12000/17168 (70%)]\tLoss: 1.313037\n",
      "Train Epoch: 3 [12160/17168 (71%)]\tLoss: 1.340866\n",
      "Train Epoch: 3 [12320/17168 (72%)]\tLoss: 1.140864\n",
      "Train Epoch: 3 [12480/17168 (73%)]\tLoss: 1.485532\n",
      "Train Epoch: 3 [12640/17168 (74%)]\tLoss: 1.242409\n",
      "Train Epoch: 3 [12800/17168 (75%)]\tLoss: 1.287682\n",
      "Train Epoch: 3 [12960/17168 (75%)]\tLoss: 1.231357\n",
      "Train Epoch: 3 [13120/17168 (76%)]\tLoss: 1.253278\n",
      "Train Epoch: 3 [13280/17168 (77%)]\tLoss: 1.405407\n",
      "Train Epoch: 3 [13440/17168 (78%)]\tLoss: 1.303292\n",
      "Train Epoch: 3 [13600/17168 (79%)]\tLoss: 1.348230\n",
      "Train Epoch: 3 [13760/17168 (80%)]\tLoss: 1.375348\n",
      "Train Epoch: 3 [13920/17168 (81%)]\tLoss: 1.226726\n",
      "Train Epoch: 3 [14080/17168 (82%)]\tLoss: 1.421108\n",
      "Train Epoch: 3 [14240/17168 (83%)]\tLoss: 1.298095\n",
      "Train Epoch: 3 [14400/17168 (84%)]\tLoss: 2.391319\n",
      "Train Epoch: 3 [14560/17168 (85%)]\tLoss: 1.289194\n",
      "Train Epoch: 3 [14720/17168 (86%)]\tLoss: 1.121786\n",
      "Train Epoch: 3 [14880/17168 (87%)]\tLoss: 1.228412\n",
      "Train Epoch: 3 [15040/17168 (88%)]\tLoss: 1.387804\n",
      "Train Epoch: 3 [15200/17168 (89%)]\tLoss: 1.464803\n",
      "Train Epoch: 3 [15360/17168 (89%)]\tLoss: 1.350892\n",
      "Train Epoch: 3 [15520/17168 (90%)]\tLoss: 1.483047\n",
      "Train Epoch: 3 [15680/17168 (91%)]\tLoss: 1.137802\n",
      "Train Epoch: 3 [15840/17168 (92%)]\tLoss: 1.321676\n",
      "Train Epoch: 3 [16000/17168 (93%)]\tLoss: 1.246567\n",
      "Train Epoch: 3 [16160/17168 (94%)]\tLoss: 1.315513\n",
      "Train Epoch: 3 [16320/17168 (95%)]\tLoss: 1.229446\n",
      "Train Epoch: 3 [16480/17168 (96%)]\tLoss: 1.124243\n",
      "Train Epoch: 3 [16640/17168 (97%)]\tLoss: 1.510911\n",
      "Train Epoch: 3 [16800/17168 (98%)]\tLoss: 1.258499\n",
      "Train Epoch: 3 [16960/17168 (99%)]\tLoss: 1.427772\n",
      "Train Epoch: 3 [17120/17168 (100%)]\tLoss: 1.154509\n",
      "\n",
      "Test set: Average loss: 1.3712, Accuracy: 1213/3857 (31%)\n",
      "\n",
      "Train Epoch: 4 [0/17168 (0%)]\tLoss: 1.493951\n",
      "Train Epoch: 4 [160/17168 (1%)]\tLoss: 1.563265\n",
      "Train Epoch: 4 [320/17168 (2%)]\tLoss: 1.302075\n",
      "Train Epoch: 4 [480/17168 (3%)]\tLoss: 1.659892\n",
      "Train Epoch: 4 [640/17168 (4%)]\tLoss: 1.608451\n",
      "Train Epoch: 4 [800/17168 (5%)]\tLoss: 1.173582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [960/17168 (6%)]\tLoss: 1.506382\n",
      "Train Epoch: 4 [1120/17168 (7%)]\tLoss: 1.208722\n",
      "Train Epoch: 4 [1280/17168 (7%)]\tLoss: 1.318329\n",
      "Train Epoch: 4 [1440/17168 (8%)]\tLoss: 1.384972\n",
      "Train Epoch: 4 [1600/17168 (9%)]\tLoss: 1.079344\n",
      "Train Epoch: 4 [1760/17168 (10%)]\tLoss: 1.359560\n",
      "Train Epoch: 4 [1920/17168 (11%)]\tLoss: 1.523851\n",
      "Train Epoch: 4 [2080/17168 (12%)]\tLoss: 1.369179\n",
      "Train Epoch: 4 [2240/17168 (13%)]\tLoss: 1.058241\n",
      "Train Epoch: 4 [2400/17168 (14%)]\tLoss: 1.211343\n",
      "Train Epoch: 4 [2560/17168 (15%)]\tLoss: 1.103756\n",
      "Train Epoch: 4 [2720/17168 (16%)]\tLoss: 1.263960\n",
      "Train Epoch: 4 [2880/17168 (17%)]\tLoss: 1.325978\n",
      "Train Epoch: 4 [3040/17168 (18%)]\tLoss: 1.286080\n",
      "Train Epoch: 4 [3200/17168 (19%)]\tLoss: 1.237329\n",
      "Train Epoch: 4 [3360/17168 (20%)]\tLoss: 1.317142\n",
      "Train Epoch: 4 [3520/17168 (21%)]\tLoss: 1.543058\n",
      "Train Epoch: 4 [3680/17168 (21%)]\tLoss: 1.382810\n",
      "Train Epoch: 4 [3840/17168 (22%)]\tLoss: 1.444353\n",
      "Train Epoch: 4 [4000/17168 (23%)]\tLoss: 1.165121\n",
      "Train Epoch: 4 [4160/17168 (24%)]\tLoss: 1.256845\n",
      "Train Epoch: 4 [4320/17168 (25%)]\tLoss: 1.283731\n",
      "Train Epoch: 4 [4480/17168 (26%)]\tLoss: 1.540198\n",
      "Train Epoch: 4 [4640/17168 (27%)]\tLoss: 1.345834\n",
      "Train Epoch: 4 [4800/17168 (28%)]\tLoss: 1.374408\n",
      "Train Epoch: 4 [4960/17168 (29%)]\tLoss: 1.273666\n",
      "Train Epoch: 4 [5120/17168 (30%)]\tLoss: 1.232039\n",
      "Train Epoch: 4 [5280/17168 (31%)]\tLoss: 1.093878\n",
      "Train Epoch: 4 [5440/17168 (32%)]\tLoss: 1.327764\n",
      "Train Epoch: 4 [5600/17168 (33%)]\tLoss: 1.266666\n",
      "Train Epoch: 4 [5760/17168 (34%)]\tLoss: 1.136614\n",
      "Train Epoch: 4 [5920/17168 (34%)]\tLoss: 1.357866\n",
      "Train Epoch: 4 [6080/17168 (35%)]\tLoss: 1.088512\n",
      "Train Epoch: 4 [6240/17168 (36%)]\tLoss: 1.247655\n",
      "Train Epoch: 4 [6400/17168 (37%)]\tLoss: 1.415846\n",
      "Train Epoch: 4 [6560/17168 (38%)]\tLoss: 1.002165\n",
      "Train Epoch: 4 [6720/17168 (39%)]\tLoss: 1.270887\n",
      "Train Epoch: 4 [6880/17168 (40%)]\tLoss: 1.135063\n",
      "Train Epoch: 4 [7040/17168 (41%)]\tLoss: 1.203554\n",
      "Train Epoch: 4 [7200/17168 (42%)]\tLoss: 1.302779\n",
      "Train Epoch: 4 [7360/17168 (43%)]\tLoss: 1.239842\n",
      "Train Epoch: 4 [7520/17168 (44%)]\tLoss: 1.280845\n",
      "Train Epoch: 4 [7680/17168 (45%)]\tLoss: 1.392090\n",
      "Train Epoch: 4 [7840/17168 (46%)]\tLoss: 1.572968\n",
      "Train Epoch: 4 [8000/17168 (47%)]\tLoss: 1.163601\n",
      "Train Epoch: 4 [8160/17168 (48%)]\tLoss: 1.361156\n",
      "Train Epoch: 4 [8320/17168 (48%)]\tLoss: 1.326616\n",
      "Train Epoch: 4 [8480/17168 (49%)]\tLoss: 1.250816\n",
      "Train Epoch: 4 [8640/17168 (50%)]\tLoss: 1.199589\n",
      "Train Epoch: 4 [8800/17168 (51%)]\tLoss: 1.359462\n",
      "Train Epoch: 4 [8960/17168 (52%)]\tLoss: 1.114627\n",
      "Train Epoch: 4 [9120/17168 (53%)]\tLoss: 1.377875\n",
      "Train Epoch: 4 [9280/17168 (54%)]\tLoss: 1.182580\n",
      "Train Epoch: 4 [9440/17168 (55%)]\tLoss: 1.291782\n",
      "Train Epoch: 4 [9600/17168 (56%)]\tLoss: 1.229041\n",
      "Train Epoch: 4 [9760/17168 (57%)]\tLoss: 1.392914\n",
      "Train Epoch: 4 [9920/17168 (58%)]\tLoss: 1.400480\n",
      "Train Epoch: 4 [10080/17168 (59%)]\tLoss: 1.402515\n",
      "Train Epoch: 4 [10240/17168 (60%)]\tLoss: 1.445264\n",
      "Train Epoch: 4 [10400/17168 (61%)]\tLoss: 1.170851\n",
      "Train Epoch: 4 [10560/17168 (62%)]\tLoss: 1.451129\n",
      "Train Epoch: 4 [10720/17168 (62%)]\tLoss: 1.281804\n",
      "Train Epoch: 4 [10880/17168 (63%)]\tLoss: 1.329527\n",
      "Train Epoch: 4 [11040/17168 (64%)]\tLoss: 1.292797\n",
      "Train Epoch: 4 [11200/17168 (65%)]\tLoss: 1.845755\n",
      "Train Epoch: 4 [11360/17168 (66%)]\tLoss: 1.330273\n",
      "Train Epoch: 4 [11520/17168 (67%)]\tLoss: 1.124799\n",
      "Train Epoch: 4 [11680/17168 (68%)]\tLoss: 1.435460\n",
      "Train Epoch: 4 [11840/17168 (69%)]\tLoss: 1.278168\n",
      "Train Epoch: 4 [12000/17168 (70%)]\tLoss: 1.310521\n",
      "Train Epoch: 4 [12160/17168 (71%)]\tLoss: 1.918823\n",
      "Train Epoch: 4 [12320/17168 (72%)]\tLoss: 1.178304\n",
      "Train Epoch: 4 [12480/17168 (73%)]\tLoss: 1.098204\n",
      "Train Epoch: 4 [12640/17168 (74%)]\tLoss: 1.137821\n",
      "Train Epoch: 4 [12800/17168 (75%)]\tLoss: 1.086397\n",
      "Train Epoch: 4 [12960/17168 (75%)]\tLoss: 1.275405\n",
      "Train Epoch: 4 [13120/17168 (76%)]\tLoss: 1.296971\n",
      "Train Epoch: 4 [13280/17168 (77%)]\tLoss: 1.258856\n",
      "Train Epoch: 4 [13440/17168 (78%)]\tLoss: 1.185097\n",
      "Train Epoch: 4 [13600/17168 (79%)]\tLoss: 1.306873\n",
      "Train Epoch: 4 [13760/17168 (80%)]\tLoss: 1.102525\n",
      "Train Epoch: 4 [13920/17168 (81%)]\tLoss: 1.145464\n",
      "Train Epoch: 4 [14080/17168 (82%)]\tLoss: 1.250182\n",
      "Train Epoch: 4 [14240/17168 (83%)]\tLoss: 1.051831\n",
      "Train Epoch: 4 [14400/17168 (84%)]\tLoss: 1.202642\n",
      "Train Epoch: 4 [14560/17168 (85%)]\tLoss: 1.263095\n",
      "Train Epoch: 4 [14720/17168 (86%)]\tLoss: 1.033999\n",
      "Train Epoch: 4 [14880/17168 (87%)]\tLoss: 1.135435\n",
      "Train Epoch: 4 [15040/17168 (88%)]\tLoss: 1.257276\n",
      "Train Epoch: 4 [15200/17168 (89%)]\tLoss: 1.184165\n",
      "Train Epoch: 4 [15360/17168 (89%)]\tLoss: 1.297123\n",
      "Train Epoch: 4 [15520/17168 (90%)]\tLoss: 1.320671\n",
      "Train Epoch: 4 [15680/17168 (91%)]\tLoss: 1.267300\n",
      "Train Epoch: 4 [15840/17168 (92%)]\tLoss: 1.374894\n",
      "Train Epoch: 4 [16000/17168 (93%)]\tLoss: 1.360641\n",
      "Train Epoch: 4 [16160/17168 (94%)]\tLoss: 1.257281\n",
      "Train Epoch: 4 [16320/17168 (95%)]\tLoss: 1.691358\n",
      "Train Epoch: 4 [16480/17168 (96%)]\tLoss: 1.304264\n",
      "Train Epoch: 4 [16640/17168 (97%)]\tLoss: 1.268186\n",
      "Train Epoch: 4 [16800/17168 (98%)]\tLoss: 1.301139\n",
      "Train Epoch: 4 [16960/17168 (99%)]\tLoss: 1.422746\n",
      "Train Epoch: 4 [17120/17168 (100%)]\tLoss: 1.320099\n",
      "\n",
      "Test set: Average loss: 1.3647, Accuracy: 1245/3857 (32%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
